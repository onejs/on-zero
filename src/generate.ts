import { createHash } from 'node:crypto'
import { existsSync, mkdirSync, readFileSync, readdirSync, writeFileSync } from 'node:fs'
import { basename, resolve } from 'node:path'

const hash = (s: string) => createHash('sha256').update(s).digest('hex')

let generateCache: Record<string, string> = {}
let generateCachePath = ''

function getCacheDir() {
  let dir = process.cwd()
  while (dir !== '/') {
    const nm = resolve(dir, 'node_modules')
    if (existsSync(nm)) {
      const cacheDir = resolve(nm, '.on-zero')
      if (!existsSync(cacheDir)) {
        mkdirSync(cacheDir, { recursive: true })
      }
      return cacheDir
    }
    dir = resolve(dir, '..')
  }
  return null
}

function loadCache() {
  const cacheDir = getCacheDir()
  if (!cacheDir) return
  generateCachePath = resolve(cacheDir, 'generate-cache.json')
  try {
    generateCache = JSON.parse(readFileSync(generateCachePath, 'utf-8'))
  } catch {
    generateCache = {}
  }
}

function saveCache() {
  if (generateCachePath) {
    writeFileSync(generateCachePath, JSON.stringify(generateCache) + '\n', 'utf-8')
  }
}

function writeFileIfChanged(filePath: string, content: string): boolean {
  const contentHash = hash(content)
  const cachedHash = generateCache[filePath]

  if (cachedHash === contentHash && existsSync(filePath)) {
    return false
  }

  writeFileSync(filePath, content, 'utf-8')
  generateCache[filePath] = contentHash
  return true
}

function generateModelsFile(modelFiles: string[]) {
  const modelNames = modelFiles.map((f) => basename(f, '.ts')).sort()
  const getImportName = (name: string) => (name === 'user' ? 'userPublic' : name)

  const imports = modelNames
    .map((name) => `import * as ${getImportName(name)} from '../models/${name}'`)
    .join('\n')

  const sortedByImportName = [...modelNames].sort((a, b) =>
    getImportName(a).localeCompare(getImportName(b))
  )
  const modelsObj = `export const models = {\n${sortedByImportName.map((name) => `  ${getImportName(name)},`).join('\n')}\n}`

  const hmrBoundary = `
if (import.meta.hot) {
  import.meta.hot.accept()
}
`

  return `// auto-generated by: on-zero generate\n${imports}\n\n${modelsObj}\n${hmrBoundary}`
}

function generateTypesFile(modelFiles: string[]) {
  const modelNames = modelFiles.map((f) => basename(f, '.ts')).sort()
  const getSchemaName = (name: string) => (name === 'user' ? 'userPublic' : name)

  const typeExports = modelNames
    .map((name) => {
      const pascalName = name.charAt(0).toUpperCase() + name.slice(1)
      const schemaName = getSchemaName(name)
      return `export type ${pascalName} = TableInsertRow<typeof schema.${schemaName}>\nexport type ${pascalName}Update = TableUpdateRow<typeof schema.${schemaName}>`
    })
    .join('\n\n')

  return `import type { TableInsertRow, TableUpdateRow } from 'on-zero'\nimport type * as schema from './tables'\n\n${typeExports}\n`
}

function generateTablesFile(modelFiles: string[]) {
  const modelNames = modelFiles.map((f) => basename(f, '.ts')).sort()
  const getExportName = (name: string) => (name === 'user' ? 'userPublic' : name)

  const exports = modelNames
    .map((name) => `export { schema as ${getExportName(name)} } from '../models/${name}'`)
    .join('\n')

  return `// auto-generated by: on-zero generate\n// this is separate from models as otherwise you end up with circular types :/\n\n${exports}\n`
}

function generateReadmeFile() {
  return `# generated

this folder is auto-generated by on-zero. do not edit files here directly.

## what's generated

- \`models.ts\` - exports all models from ../models
- \`types.ts\` - typescript types derived from table schemas
- \`tables.ts\` - exports table schemas for type inference
- \`groupedQueries.ts\` - namespaced query re-exports for client setup
- \`syncedQueries.ts\` - namespaced syncedQuery wrappers for server setup

## usage guidelines

**do not import generated files outside of the data folder.**

### queries

write your queries as plain functions in \`../queries/\` and import them directly:

\`\`\`ts
// ‚úÖ good - import from queries
import { channelMessages } from '~/data/queries/message'
\`\`\`

the generated query files are only used internally by zero client/server setup.

### types

you can import types from this folder, but prefer re-exporting from \`../types.ts\`:

\`\`\`ts
// ‚ùå okay but not preferred
import type { Message } from '~/data/generated/types'

// ‚úÖ better - re-export from types.ts
import type { Message } from '~/data/types'
\`\`\`

## regeneration

files are regenerated when you run:

\`\`\`bash
bun on-zero generate
\`\`\`

or in watch mode:

\`\`\`bash
bun on-zero generate --watch
\`\`\`

## more info

see the [on-zero readme](./node_modules/on-zero/README.md) for full documentation.
`
}

function generateGroupedQueriesFile(
  queries: Array<{ name: string; sourceFile: string }>
) {
  const sortedFiles = [...new Set(queries.map((q) => q.sourceFile))].sort()

  const exports = sortedFiles
    .map((file) => `export * as ${file} from '../queries/${file}'`)
    .join('\n')

  return `/**
 * auto-generated by: on-zero generate
 *
 * grouped query re-exports for minification-safe query identity.
 * this file re-exports all query modules - while this breaks tree-shaking,
 * queries are typically small and few in number even in larger apps.
 */
${exports}
`
}

function generateSyncedQueriesFile(
  queries: Array<{
    name: string
    params: string
    valibotCode: string
    sourceFile: string
  }>
) {
  const queryByFile = new Map<string, typeof queries>()
  for (const q of queries) {
    if (!queryByFile.has(q.sourceFile)) {
      queryByFile.set(q.sourceFile, [])
    }
    queryByFile.get(q.sourceFile)!.push(q)
  }

  const sortedFiles = Array.from(queryByFile.keys()).sort()

  const imports = `// auto-generated by: on-zero generate
// server-side query definitions with validators
import { defineQuery, defineQueries } from '@rocicorp/zero'
import * as v from 'valibot'
import * as Queries from './groupedQueries'
`

  const namespaceDefs = sortedFiles
    .map((file) => {
      const fileQueries = queryByFile
        .get(file)!
        .sort((a, b) => a.name.localeCompare(b.name))

      const queryDefs = fileQueries
        .map((q) => {
          const lines = q.valibotCode.split('\n').filter((l) => l.trim())
          const schemaLineIndex = lines.findIndex((l) =>
            l.startsWith('export const QueryParams')
          )

          let validatorDef = ''
          if (schemaLineIndex !== -1) {
            const schemaLines: string[] = []
            let openBraces = 0
            let started = false

            for (let i = schemaLineIndex; i < lines.length; i++) {
              const line = lines[i]!
              const cleaned = started
                ? line
                : line.replace('export const QueryParams = ', '')
              schemaLines.push(cleaned)
              started = true

              openBraces += (cleaned.match(/\{/g) || []).length
              openBraces -= (cleaned.match(/\}/g) || []).length
              openBraces += (cleaned.match(/\(/g) || []).length
              openBraces -= (cleaned.match(/\)/g) || []).length

              if (openBraces === 0 && schemaLines.length > 0) {
                break
              }
            }
            validatorDef = schemaLines.join('\n')
          }

          if (q.params === 'void' || !validatorDef) {
            return `  ${q.name}: defineQuery(() => Queries.${file}.${q.name}()),`
          }

          const indentedValidator = validatorDef
            .split('\n')
            .map((line, i) => (i === 0 ? line : `    ${line}`))
            .join('\n')

          return `  ${q.name}: defineQuery(
    ${indentedValidator},
    ({ args }) => Queries.${file}.${q.name}(args)
  ),`
        })
        .join('\n')

      return `const ${file} = {\n${queryDefs}\n}`
    })
    .join('\n\n')

  const queriesObject = sortedFiles.map((file) => `  ${file},`).join('\n')

  return `${imports}
${namespaceDefs}

export const queries = defineQueries({
${queriesObject}
})
`
}

export interface GenerateOptions {
  /** base data directory */
  dir: string
  /** run after generation */
  after?: string
  /** suppress output */
  silent?: boolean
}

export interface WatchOptions extends GenerateOptions {
  /** debounce delay in ms */
  debounce?: number
}

export interface GenerateResult {
  filesChanged: number
  modelCount: number
  schemaCount: number
  queryCount: number
}

export async function generate(options: GenerateOptions): Promise<GenerateResult> {
  const { dir, after, silent } = options
  const baseDir = resolve(dir)
  const modelsDir = resolve(baseDir, 'models')
  const generatedDir = resolve(baseDir, 'generated')
  const queriesDir = resolve(baseDir, 'queries')

  if (!existsSync(generatedDir)) {
    mkdirSync(generatedDir, { recursive: true })
  }

  loadCache()

  const allModelFiles = readdirSync(modelsDir)
    .filter((f) => f.endsWith('.ts'))
    .sort()

  const filesWithSchema = allModelFiles.filter((f) =>
    readFileSync(resolve(modelsDir, f), 'utf-8').includes('export const schema = table(')
  )

  const writeResults = [
    writeFileIfChanged(
      resolve(generatedDir, 'models.ts'),
      generateModelsFile(allModelFiles)
    ),
    writeFileIfChanged(
      resolve(generatedDir, 'types.ts'),
      generateTypesFile(filesWithSchema)
    ),
    writeFileIfChanged(
      resolve(generatedDir, 'tables.ts'),
      generateTablesFile(filesWithSchema)
    ),
    writeFileIfChanged(resolve(generatedDir, 'README.md'), generateReadmeFile()),
  ]

  let filesChanged = writeResults.filter(Boolean).length
  let queryCount = 0

  // generate query files if queries directory exists
  if (existsSync(queriesDir)) {
    const ts = await import('typescript')
    const { ModelToValibot } = await import('@sinclair/typebox-codegen/model/index.js')
    const { TypeScriptToModel } =
      await import('@sinclair/typebox-codegen/typescript/index.js')

    const queryFiles = readdirSync(queriesDir).filter((f) => f.endsWith('.ts'))

    const allQueries: Array<{
      name: string
      params: string
      valibotCode: string
      sourceFile: string
    }> = []

    for (const file of queryFiles) {
      const filePath = resolve(queriesDir, file)
      const fileBaseName = basename(file, '.ts')

      try {
        const content = readFileSync(filePath, 'utf-8')
        const sourceFile = ts.createSourceFile(
          filePath,
          content,
          ts.ScriptTarget.Latest,
          true
        )

        ts.forEachChild(sourceFile, (node) => {
          if (ts.isVariableStatement(node)) {
            const exportModifier = node.modifiers?.find(
              (m) => m.kind === ts.SyntaxKind.ExportKeyword
            )
            if (!exportModifier) return

            const declaration = node.declarationList.declarations[0]
            if (!declaration || !ts.isVariableDeclaration(declaration)) return

            const name = declaration.name.getText(sourceFile)
            if (name === 'permission') return

            if (declaration.initializer && ts.isArrowFunction(declaration.initializer)) {
              const params = declaration.initializer.parameters
              let paramType = 'void'

              if (params.length > 0) {
                const param = params[0]!
                paramType = param.type?.getText(sourceFile) || 'unknown'
              }

              try {
                const typeString = `type QueryParams = ${paramType}`
                const model = TypeScriptToModel.Generate(typeString)
                const valibotCode = ModelToValibot.Generate(model)

                allQueries.push({
                  name,
                  params: paramType,
                  valibotCode,
                  sourceFile: fileBaseName,
                })
              } catch (err) {
                if (!silent) console.error(`‚úó ${name}: ${err}`)
              }
            }
          }
        })
      } catch (err) {
        if (!silent) console.error(`Error processing ${file}:`, err)
      }
    }

    queryCount = allQueries.length

    const groupedChanged = writeFileIfChanged(
      resolve(generatedDir, 'groupedQueries.ts'),
      generateGroupedQueriesFile(allQueries)
    )
    const syncedChanged = writeFileIfChanged(
      resolve(generatedDir, 'syncedQueries.ts'),
      generateSyncedQueriesFile(allQueries)
    )

    if (groupedChanged) filesChanged++
    if (syncedChanged) filesChanged++
  }

  if (filesChanged > 0 && !silent) {
    console.info(
      `‚úì ${allModelFiles.length} models (${filesWithSchema.length} schemas)${queryCount ? `, ${queryCount} queries` : ''}`
    )
  }

  // run after command
  if (filesChanged > 0 && after) {
    const { execSync } = await import('node:child_process')
    try {
      execSync(after, {
        stdio: 'inherit',
        env: { ...process.env, ON_ZERO_GENERATED_DIR: generatedDir },
      })
    } catch (err) {
      if (!silent) console.error(`Error running after command: ${err}`)
    }
  }

  saveCache()

  return {
    filesChanged,
    modelCount: allModelFiles.length,
    schemaCount: filesWithSchema.length,
    queryCount,
  }
}

export async function watch(options: WatchOptions) {
  const { dir, debounce = 1000 } = options
  const baseDir = resolve(dir)
  const modelsDir = resolve(baseDir, 'models')
  const queriesDir = resolve(baseDir, 'queries')
  const generatedDir = resolve(baseDir, 'generated')

  // initial run (silent)
  await generate({ ...options, silent: true })
  console.info('üëÄ watching...\n')

  const chokidar = await import('chokidar')

  let debounceTimer: ReturnType<typeof setTimeout> | null = null

  const debouncedRegenerate = (path: string, event: string) => {
    if (debounceTimer) clearTimeout(debounceTimer)
    console.info(`\n${event} ${path}`)
    debounceTimer = setTimeout(() => {
      generate({ ...options, silent: false })
    }, debounce)
  }

  const watcher = chokidar.watch([modelsDir, queriesDir], {
    persistent: true,
    ignoreInitial: true,
    ignored: [generatedDir],
  })

  watcher.on('change', (path) => debouncedRegenerate(path, 'üìù'))
  watcher.on('add', (path) => debouncedRegenerate(path, '‚ûï'))
  watcher.on('unlink', (path) => debouncedRegenerate(path, 'üóëÔ∏è '))

  return watcher
}
